{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import requests\n",
                "import os\n",
                "import opendatasets as od\n",
                "import zipfile\n",
                "import tensorflow as tf\n",
                "from pathlib import Path\n",
                "import shutil\n",
                "import random\n",
                "import hashlib\n",
                "import cv2\n",
                "from matplotlib import pyplot as plt\n",
                "import re\n",
                "import ultralytics\n",
                "from ultralytics import YOLO"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First of all, we download the files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Assign the Kaggle data set URL into variable\n",
                "dataset = \"https://www.kaggle.com/datasets/youthamj/captchaobjectdetection\"\n",
                "# Using opendatasets let's download the data sets\n",
                "od.download(dataset, data_dir=\"../data/raw/\", force=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we calculate the number of files donwloaded."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dir = \"../data/raw/captchaobjectdetection\"\n",
                "\n",
                "print(sum(1 for file in Path(data_dir).iterdir() if file.is_file()))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Then, we calculate the number of images (.png extension) and text files (.txt extension)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(sum(1 for im in Path(data_dir).glob(\"*.png\")))\n",
                "print(sum(1 for im in Path(data_dir).glob(\"*.txt\")))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can observe that the number of images and files differ by one since there are 200,001 files in total, 100.000 images and 100.001 text files. Therefore, we have one extra text file aside from those associated with each image.\n",
                "\n",
                "The extra file is all_sequences.txt, that contains the relationship between the name of the image/text file and the characters that contains.\n",
                "\n",
                "We will use this file to asociate the characters in each row to the number asociated to it in the YOLO files."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The content of the text files can be duplicated since there could be two different images with the same characters to decipher, so we only check there are no duplicates in our images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def hashfile(file_path):\n",
                "    hasher = hashlib.sha256()\n",
                "    with open(file_path, 'rb') as f:\n",
                "        buf = f.read()\n",
                "        hasher.update(buf)\n",
                "    return hasher.hexdigest()\n",
                "\n",
                "\n",
                "hashes = pd.DataFrame(columns=[\"filename\",\"hash\"])\n",
                "hashes_dup = pd.DataFrame(columns=[\"filename\",\"hash\"])\n",
                "\n",
                "for filename in Path(data_dir).glob(\"*.png\"):\n",
                "  file_hash = hashfile(filename)\n",
                "  if (hashes[\"hash\"] != file_hash).all():\n",
                "    hashes.loc[len(hashes)] = [filename, file_hash]\n",
                "  else:\n",
                "    hashes_dup.loc[len(hashes_dup)] = [filename, file_hash]\n",
                "\n",
                "if hashes_dup.empty:\n",
                "  print(\"No duplicates in the dataset.\")\n",
                "else:\n",
                "  print(hashes_dup)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's check then an inmage, and it's bounding boxes, to see everything goes as expected in the YOLO files."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we check as an example a random image and its bounding box, to check the values are defined as expected."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_img(img_dir, txt_dir):\n",
                "    image = cv2.imread(img_dir)\n",
                "    image_hight = image.shape[0]\n",
                "    image_width = image.shape[1]\n",
                "\n",
                "    with open(txt_dir, 'r', encoding='utf-8') as f:\n",
                "        text_list = [list(map(float, line.strip().split())) for line in f]\n",
                "\n",
                "    for i in range(len(text_list)):\n",
                "        x0 = text_list[i][1] - text_list[1][3] / 2\n",
                "        x1 = text_list[i][1] + text_list[i][3] / 2\n",
                "        y0 = text_list[i][2] - text_list[i][4] / 2\n",
                "        y1 = text_list[i][2] + text_list[i][4] / 2\n",
                "\n",
                "        start_point = (int(x0*image_width), int(y0*image_hight))\n",
                "        end_point = (int(x1*image_width), int(y1*image_hight))\n",
                "\n",
                "        img = cv2.rectangle(image, start_point, end_point, color=(255, 0, 0), thickness=2)\n",
                "\n",
                "    plt.imshow(img)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "img_dir = data_dir + \"/10084.png\"\n",
                "txt_dir = data_dir + \"/10084.txt\"\n",
                "\n",
                "plot_img(img_dir, txt_dir)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And the most important thing, to extract the relationship between the characters of every image, and the class of the YOLO files associated to it (the base to construct the classes of our dataset.yaml file)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "files_all = \"../data/raw/captchaobjectdetection/all_sequences.txt\"\n",
                "\n",
                "chars_per_img = []\n",
                "with open(files_all, \"r\", encoding=\"utf-8\") as fa:\n",
                "    chars_per_img = [line.strip().split(\",\") for line in fa]\n",
                "\n",
                "files = \"../data/raw/captchaobjectdetection/\"\n",
                "char_files = pd.DataFrame(columns=[\"char\",\"class\"])\n",
                "\n",
                "for file in Path(files).glob(\"*.txt\"):\n",
                "    if file.is_file() and file.name != \"all_sequences.txt\":\n",
                "        with open(file, \"r\", encoding=\"utf-8\") as f:  \n",
                "            values = [line.strip().split()[0] for line in f]\n",
                "\n",
                "        filename = file.stem  \n",
                "        \n",
                "        chars = next((pair[1] for pair in chars_per_img if pair[0] == filename), [])\n",
                "\n",
                "        temp_df = pd.DataFrame({'char': values, 'class': list(chars)})\n",
                "        char_files = pd.concat([char_files, temp_df], ignore_index=True)\n",
                "\n",
                "print(char_files.value_counts().reset_index().sort_values(\"class\", ascending=True))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We noticed that there are some characters missing: iIlLoO01\n",
                "It makes sense, so these are characters so easy to confuse them."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Finally, it's time to create the folders to divide the files in txt and images, and then split then in 3 subsets of train, validation and test, in a rate of 60-20-20."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs(\"../data/raw/images\")\n",
                "os.makedirs(\"../data/raw/labels\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for im in Path(\"data_dir\").glob(\"*.png\"):\n",
                "    shutil.move(im, os.path.join(\"../data/raw/images\", im.name))\n",
                "\n",
                "for im in Path(\"data_dir\").glob(\"*.txt\"):\n",
                "    shutil.move(im, os.path.join(\"../data/raw/labels\", im.name))\n",
                "\n",
                "for im in Path(\"../data/raw/labels\").glob(\"all_sequences.txt\"):\n",
                "    shutil.move(im, os.path.join(\"data_dir\", im.name))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs(\"../data/raw/images/train\")\n",
                "os.makedirs(\"../data/raw/images/val\")\n",
                "os.makedirs(\"../data/raw/images/test\")\n",
                "\n",
                "os.makedirs(\"../data/raw/labels/train\")\n",
                "os.makedirs(\"../data/raw/labels/val\")\n",
                "os.makedirs(\"../data/raw/labels/test\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "origin = \"../data/raw/images\"\n",
                "destiny_train = \"../data/raw/images/train\"\n",
                "destiny_val = \"../data/raw/images/val\"\n",
                "destiny_test = \"../data/raw/images/test\"\n",
                "\n",
                "files = [f for f in os.listdir(origin) if os.path.isfile(os.path.join(origin, f))]\n",
                "    \n",
                "size_to_move = int(len(files) * (20 / 100))\n",
                "    \n",
                "files_to_move_val = random.sample(files, size_to_move)\n",
                "\n",
                "for file in files_to_move_val:\n",
                "    shutil.move(os.path.join(origin, file), os.path.join(destiny_val, file))\n",
                "\n",
                "files = [f for f in os.listdir(origin) if os.path.isfile(os.path.join(origin, f))]\n",
                "files_to_move_test = random.sample(files, size_to_move)\n",
                "\n",
                "for file in files_to_move_test:\n",
                "    shutil.move(os.path.join(origin, file), os.path.join(destiny_test, file))\n",
                "\n",
                "for im in Path(\"../data/raw/images\").glob(\"*.png\"):\n",
                "    shutil.move(im, os.path.join(\"../data/raw/images/train\", im.name))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "destiny_train_im = \"../data/raw/images/train\"\n",
                "destiny_val_im = \"../data/raw/images/val\"\n",
                "destiny_test_im = \"../data/raw/images/test\"\n",
                "\n",
                "origin_txt = \"../data/raw/labels\"\n",
                "destiny_train_txt = \"../data/raw/labels/train\"\n",
                "destiny_val_txt = \"../data/raw/labels/val\"\n",
                "destiny_test_txt = \"../data/raw/labels/test\"\n",
                "\n",
                "im_train = {os.path.splitext(f)[0] for f in os.listdir(destiny_train_im) if os.path.isfile(os.path.join(destiny_train_im, f))}\n",
                "im_val = {os.path.splitext(f)[0] for f in os.listdir(destiny_val_im) if os.path.isfile(os.path.join(destiny_val_im, f))}\n",
                "im_test = {os.path.splitext(f)[0] for f in os.listdir(destiny_test_im) if os.path.isfile(os.path.join(destiny_test_im, f))}\n",
                "\n",
                "for file in os.listdir(origin_txt):\n",
                "    path = os.path.join(origin_txt, file)\n",
                "\n",
                "    if os.path.isfile(path):\n",
                "        root, _ = os.path.splitext(file)\n",
                "\n",
                "        # Si el nombre coincide con los nombres de la carpeta de imágenes, moverlo\n",
                "        if root in im_train:\n",
                "            shutil.move(path, os.path.join(destiny_train_txt, file))\n",
                "        \n",
                "        elif root in im_val:\n",
                "            shutil.move(path, os.path.join(destiny_val_txt, file))\n",
                "\n",
                "        elif root in im_test:\n",
                "            shutil.move(path, os.path.join(destiny_test_txt, file))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's check the folders have the number of files expected."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(len(os.listdir(destiny_train_im)))\n",
                "print(len(os.listdir(destiny_val_im)))\n",
                "print(len(os.listdir(destiny_test_im)))\n",
                "\n",
                "print(len(os.listdir(destiny_train_txt)))\n",
                "print(len(os.listdir(destiny_val_txt)))\n",
                "print(len(os.listdir(destiny_test_txt)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's begin with the YOLO model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = YOLO(\"yolov11x.pt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First of all, we train the model with our dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = model.train(\n",
                "    data=\"./dataset.yaml\",\n",
                "    epochs=50,\n",
                "    imgsz=640,\n",
                "    batch=-1,\n",
                "    device=0\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "When we try to train the model, we can see the following error:\n",
                "\n",
                "val: WARNING  ..\\captcha-processor\\data\\raw\\images\\val\\9998.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333]\n",
                "train: WARNING  ..\\captcha-processor\\data\\raw\\images\\train\\99960.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0333]\n",
                "\n",
                "It seems that thousands of the YOLO files have at least, one value bigger than 1, wich is not valid, due to value normalization.\n",
                "\n",
                "Let's copy some of this images and txt in the original folder, soy we can see whats happenning, and what can we do."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "img_dir = \"../data/interim/10193.png\"\n",
                "txt_dir = \"../data/interim/10193.txt\"\n",
                "\n",
                "plot_img(img_dir, txt_dir)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's compare the results whith the YOLO file normalized (replacing any value bigger than one, with one)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "img_dir = \"../data/interim/10193.png\"\n",
                "txt_dir = \"../data/interim/10193_normalized.txt\"\n",
                "\n",
                "plot_img(img_dir, txt_dir)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can notice that the rectangles stay the same, but the values are now valid in YOLO files, so they have no values outside 0 to 1."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "So, the key now is to replace every value bigger with one, to one, in every text file all along the YOLO files."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First of all in this step is to create a back up of the original txt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "shutil.copytree(\"../data/raw/labels/\", \"../data/raw/captchaobjectdetection\", dirs_exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And then, modify the files to normalize values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dir = \"../data/raw/labels\"\n",
                "\n",
                "for file in Path(dir).rglob(\"*.txt\"):   \n",
                "    with open(file, \"r+\", encoding=\"utf-8\") as f:\n",
                "        lines = f.readlines()\n",
                "        f.seek(0)  \n",
                "        for line in lines:\n",
                "            values = list(map(str, line.strip().split()))\n",
                "            values_to_change = [\"1\" if float(x) > 1 else x for x in values[1:]]\n",
                "            f.write(\" \".join([values[0]] + values_to_change) + \"\\n\")\n",
                "        f.truncate()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's try again the YOLO training, in order to see if our changes normalizing the txt file values have solved the problem."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = model.train(\n",
                "    data=\"./dataset.yaml\",\n",
                "    epochs=50,\n",
                "    imgsz=640,\n",
                "    batch=-1,\n",
                "    device=0\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Then, we save the model in onnx format"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.export(format=\"onnx\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "and validate it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_val = model.val(data=\"./dataset.yaml\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Finally, we create some functions that processes the image using the YOLO model, and shows the boxes and the classes it detects."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def capcha_prediction(final_results, names):\n",
                "  \"\"\"\n",
                "  Predicts the CAPTCHA text from object detection results by extracting and sorting character detections.\n",
                "\n",
                "  Parameters:\n",
                "  final_results (list): A list of detection results, where each result contains bounding boxes and class IDs.\n",
                "  names (list): A list of class names corresponding to detected character indices.\n",
                "\n",
                "  Returns:\n",
                "  str: The predicted CAPTCHA text based on detected characters sorted from left to right.\n",
                "  \"\"\"\n",
                "  detection_string = \"\"\n",
                "  for result in final_results:\n",
                "      boxes = result.boxes.xyxy\n",
                "      class_ids = result.boxes.cls\n",
                "\n",
                "      detections = sorted(zip(boxes, class_ids), key=lambda x: x[0][0])\n",
                "   \n",
                "      for box, class_id in detections:\n",
                "          detection_string += f\"{names[int(class_id)]}\"\n",
                "\n",
                "  return detection_string\n",
                "\n",
                "\n",
                "def captcha_boxes_prediction(final_results, image_path):\n",
                "  \"\"\"\n",
                "  Draws bounding boxes around detected CAPTCHA characters in an image.\n",
                "\n",
                "  Parameters:\n",
                "  final_results (list): A list of detection results containing bounding boxes.\n",
                "  image_path (str): Path to the image file.\n",
                "\n",
                "  Returns:\n",
                "  numpy.ndarray: The image with drawn bounding boxes.\n",
                "  \"\"\"\n",
                "  image = cv2.imread(image_path)\n",
                "  image_hight = image.shape[0]\n",
                "  image_width = image.shape[1]\n",
                "\n",
                "  for result in final_results:\n",
                "    boxes = result.boxes.xyxy\n",
                "\n",
                "    for box in boxes:\n",
                "      x0, y0, x1, y1 = map(int, box)  # Convertir a enteros\n",
                "      img = cv2.rectangle(image, (x0, y0), (x1, y1), (255, 255, 0), 2)\n",
                "\n",
                "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "  plt.imshow(img)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's check it out!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_final = YOLO(\"./runs/detect/train2/weights/best.pt\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_image_path = \"../data/raw/images/test/65.png\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = model_final(test_image_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(capcha_prediction(results, model_final.names))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "captcha_boxes_prediction(results,test_image_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It works!!!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.13"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
